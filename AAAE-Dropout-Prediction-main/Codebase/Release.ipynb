{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6fe367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright © 2025 Yao Yuzhuo (yaoyuzhuo6@gmail.com). For academic research only. Commercial use is strictly prohibited.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, accuracy_score, mean_absolute_error\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import tree\n",
    "from six import StringIO\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "from termcolor import colored as cl\n",
    "from scipy.stats import norm\n",
    "from sklearn import preprocessing\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ccbf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (this should be after imports)\n",
    "train_data = pd.read_csv('DBS.csv', sep=';')\n",
    "test_data = pd.read_csv('DBS_2020.csv', sep=';')\n",
    "\n",
    "X_train_common = np.asarray(train_data[['access', 'tests', 'assignments']])\n",
    "y_train_common = np.asarray(train_data['graduate'])\n",
    "X_test_common = np.asarray(test_data[['access', 'tests', 'assignments']])\n",
    "y_test_common = np.asarray(test_data['graduate'])\n",
    "\n",
    "# New: Generate Table I - Descriptive Statistics for 2016-2019 Dataset\n",
    "independent_vars = train_data[['access', 'tests', 'assignments', 'exam', 'project']]\n",
    "desc_stats_2019 = independent_vars.describe()\n",
    "print(\"Table I: Descriptive Statistics of Independent Variables (Accesses, Assignments, Tests, Exam, and Project) for the 2016–2019 Dataset\")\n",
    "print(desc_stats_2019)\n",
    "\n",
    "# New: Generate Figure 2 - Correlation Matrix\n",
    "corr_matrix = train_data[['access', 'assignments', 'tests', 'exam', 'project', 'result_points']].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Figure 2: Correlation Matrix of Independent Variables and Result Points')\n",
    "plt.show()\n",
    "\n",
    "# New: Generate Table II - Descriptive Statistics for 2020 Dataset\n",
    "independent_vars_2020 = test_data[['access', 'tests', 'assignments', 'exam', 'project']]\n",
    "desc_stats_2020 = independent_vars_2020.describe()\n",
    "print(\"Table II: Descriptive Statistics of Independent Variables (Accesses, Assignments, Tests, Exam, and Project) for the 2020 Dataset\")\n",
    "print(desc_stats_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02538a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1: Decision Tree\n",
    "\n",
    "# Copy of data for this model\n",
    "X_train = np.copy(X_train_common)\n",
    "y_train = np.copy(y_train_common)\n",
    "X_test = np.copy(X_test_common)\n",
    "y_test = np.copy(y_test_common)\n",
    "\n",
    "# Standardize the data\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "# Initialize classifier\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "\n",
    "# Train the model\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate pipeline without oversampling\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=4)\n",
    "scores = cross_val_score(clf, X_test, y_test, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC (without oversampling): %.3f' % np.mean(scores))\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "oversample = SMOTE()\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "# Summarize new class distribution\n",
    "counter = Counter(y_train)\n",
    "print(\"Class distribution after SMOTE:\", counter)\n",
    "\n",
    "# Evaluate pipeline with oversampling\n",
    "scores = cross_val_score(clf, X_test, y_test, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC (with oversampling): %.3f' % np.mean(scores))\n",
    "\n",
    "# Predictions\n",
    "yhat = clf.predict(X_test)\n",
    "yhat_prob = clf.predict_proba(X_test)\n",
    "\n",
    "# Unified Evaluation\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, yhat))\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "cm = confusion_matrix(y_test, yhat)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "auc = roc_auc_score(y_test, yhat_prob[:, 1])\n",
    "print(\"AUC-ROC:\", auc)\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, yhat_prob[:, 1])\n",
    "plt.plot(fpr, tpr, label=f\"Decision Tree, AUC={auc:.2f}\")\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "\n",
    "# Visualize Decision Tree\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(clf, out_file=dot_data, filled=True, rounded=True, special_characters=True,\n",
    "                     feature_names=['access', 'tests', 'assignments'], class_names=['0', '1'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "graph.write_png('tree.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e078cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 2: Logistic Regression\n",
    "\n",
    "# Copy of data for this model\n",
    "X_train = np.copy(X_train_common)\n",
    "y_train = np.copy(y_train_common)\n",
    "X_test = np.copy(X_test_common)\n",
    "y_test = np.copy(y_test_common)\n",
    "\n",
    "# Display basic information\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "print(\"Train data columns:\", list(train_data.columns))\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nTrain graduate distribution:\\n\", train_data['graduate'].value_counts())\n",
    "print(\"Test graduate distribution:\\n\", test_data['graduate'].value_counts())\n",
    "\n",
    "# Display samples\n",
    "print(cl('\\nX_train samples:', attrs=['bold']), X_train[:5])\n",
    "print(cl('y_train samples:', attrs=['bold']), y_train[:5])\n",
    "print(cl('\\nX_test samples:', attrs=['bold']), X_test[:5])\n",
    "print(cl('y_test samples:', attrs=['bold']), y_test[:5])\n",
    "\n",
    "# Normalize test data\n",
    "scaler = StandardScaler()\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "print(\"\\nNormalized X_test description:\\n\", pd.DataFrame(X_test_scaled).describe())\n",
    "\n",
    "# Visualize original class distribution\n",
    "counter = Counter(y_train)\n",
    "print(\"\\nOriginal class distribution:\", counter)\n",
    "for label in counter:\n",
    "    row_ix = np.where(y_train == label)[0]\n",
    "    plt.scatter(X_train[row_ix, 0], X_train[row_ix, 1], label=f'Class {label}')\n",
    "plt.legend()\n",
    "plt.title(\"Original Class Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Apply SMOTE to balance training data\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# Visualize resampled class distribution\n",
    "counter_res = Counter(y_train_res)\n",
    "print(\"\\nResampled class distribution:\", counter_res)\n",
    "for label in counter_res:\n",
    "    row_ix = np.where(y_train_res == label)[0]\n",
    "    plt.scatter(X_train_res[row_ix, 0], X_train_res[row_ix, 1], label=f'Class {label}')\n",
    "plt.legend()\n",
    "plt.title(\"Resampled Class Distribution (SMOTE)\")\n",
    "plt.show()\n",
    "\n",
    "# Train Logistic Regression model\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train_res, y_train_res)\n",
    "print(cl('\\nLogistic Regression Model:', attrs=['bold']), lr_model)\n",
    "\n",
    "# Evaluate model with cross-validation\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=1)\n",
    "scores = cross_val_score(lr_model, X_test, y_test, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % np.mean(scores))\n",
    "\n",
    "# Make predictions\n",
    "yhat = lr_model.predict(X_test)\n",
    "yhat_prob = lr_model.predict_proba(X_test)\n",
    "\n",
    "# Unified Evaluation\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, yhat))\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "cm = confusion_matrix(y_test, yhat)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "auc = roc_auc_score(y_test, yhat_prob[:, 1])\n",
    "print(\"AUC-ROC:\", auc)\n",
    "\n",
    "# Confusion Matrix Plot\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, yhat)\n",
    "print(f\"\\nRecall: {100 * cnf_matrix[1, 1] / (cnf_matrix[1, 0] + cnf_matrix[1, 1]):.2f}%\")\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0, 1], title='Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, yhat_prob[:, 1])\n",
    "plt.plot(fpr, tpr, label=f\"Logistic Regression, AUC={auc:.3f}\")\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "# Fit logistic regression using statsmodels\n",
    "logit_model = smf.logit(\"graduate ~ access + assignments + tests\", data=train_data)\n",
    "results = logit_model.fit()\n",
    "print(\"\\nStatsmodels Logistic Regression Summary:\")\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561492ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 3: Naive Bayes\n",
    "\n",
    "# Copy of data for this model\n",
    "X_train = np.copy(X_train_common)\n",
    "y_train = np.copy(y_train_common)\n",
    "X_test = np.copy(X_test_common)\n",
    "y_test = np.copy(y_test_common)\n",
    "\n",
    "# Set plot size\n",
    "plt.rcParams['figure.figsize'] = (20, 10)\n",
    "\n",
    "# Print training data preview\n",
    "print(\"Training data preview:\\n\", train_data.head())\n",
    "\n",
    "# Initialize and train Naive Bayes model\n",
    "model = GaussianNB(priors=None, var_smoothing=1e-09)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model with cross-validation\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=4)\n",
    "scores = cross_val_score(model, X_test, y_test, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print(f\"\\nMean ROC AUC: {np.mean(scores):.3f}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "yhat_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Unified Evaluation\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, predictions))\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "auc = roc_auc_score(y_test, yhat_prob)\n",
    "print(\"AUC-ROC:\", auc)\n",
    "\n",
    "# Confusion Matrix Plot\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, predictions)\n",
    "recall = 100 * cnf_matrix[1, 1] / (cnf_matrix[1, 0] + cnf_matrix[1, 1])\n",
    "print(f\"\\nRecall metric in the testing dataset: {recall:.2f}%\")\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0, 1], title='Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, yhat_prob)\n",
    "plt.plot(fpr, tpr, label=f\"Naive Bayes, AUC={auc:.2f}\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0404f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 4: MLP (Improved MLP)\n",
    "\n",
    "# Copy of data for this model\n",
    "X_train = np.copy(X_train_common)\n",
    "y_train = np.copy(y_train_common)\n",
    "X_test = np.copy(X_test_common)\n",
    "y_test = np.copy(y_test_common)\n",
    "\n",
    "# Feature standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# SMOTE\n",
    "oversample = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "# To PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_res, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_res, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Split train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_tensor, y_train_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# DataLoaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# EnhancedMLP model\n",
    "class EnhancedMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, dropout_rate=0.3):\n",
    "        super(EnhancedMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        self.fc4 = nn.Linear(hidden_size3, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.dropout1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.dropout2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.dropout3(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "input_size = 3\n",
    "hidden_size1 = 128\n",
    "hidden_size2 = 64\n",
    "hidden_size3 = 32\n",
    "dropout_rate = 0.3\n",
    "\n",
    "model = EnhancedMLP(input_size, hidden_size1, hidden_size2, hidden_size3, dropout_rate)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "patience = 10\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            output = model(X_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_prob = model(X_test_tensor)\n",
    "    y_pred = (y_pred_prob > 0.5).float()\n",
    "\n",
    "# Unified Evaluation\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_tensor.numpy(), y_pred.numpy()))\n",
    "accuracy = accuracy_score(y_test_tensor.numpy(), y_pred.numpy())\n",
    "print(\"Accuracy:\", accuracy)\n",
    "cm = confusion_matrix(y_test_tensor.numpy(), y_pred.numpy())\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "auc = roc_auc_score(y_test_tensor.numpy(), y_pred_prob.numpy())\n",
    "print(\"AUC-ROC:\", auc)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Passed', 'Passed'],\n",
    "            yticklabels=['Not Passed', 'Passed'])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test_tensor.numpy(), y_pred_prob.numpy())\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'Enhanced MLP, AUC={auc:.3f}', color='darkblue')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_losses, label=\"Train Loss\", color='blue')\n",
    "plt.plot(val_losses, label=\"Val Loss\", color='orange')\n",
    "plt.title('Model Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Actual': y_test_tensor.numpy().flatten(),\n",
    "    'Predicted': y_pred.numpy().flatten(),\n",
    "    'Probability': y_pred_prob.numpy().flatten()\n",
    "})\n",
    "results.to_csv('enhanced_mlp_predictions.csv', index=False)\n",
    "print(\"\\nPredictions saved to 'enhanced_mlp_predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0828c4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 5: Neural Network\n",
    "\n",
    "# Copy of data for this model\n",
    "X_train = np.copy(X_train_common)\n",
    "y_train = np.copy(y_train_common)\n",
    "X_test = np.copy(X_test_common)\n",
    "y_test = np.copy(y_test_common)\n",
    "\n",
    "# Standardize features\n",
    "X_train = preprocessing.scale(X_train)\n",
    "X_test = preprocessing.scale(X_test)\n",
    "\n",
    "# SMOTE\n",
    "oversample = SMOTE()\n",
    "X_train_res, y_train_res = oversample.fit_resample(X_train, y_train)\n",
    "print(\"\\nResampled training data shape:\", X_train_res.shape)\n",
    "\n",
    "# To PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_res, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_res, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# MLPModel\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 10)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(10, 5)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(5, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "model = MLPModel(input_dim=3)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor)\n",
    "    y_pred_binary = (y_pred > 0.5).float()\n",
    "\n",
    "# Unified Evaluation\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_tensor.numpy(), y_pred_binary.numpy()))\n",
    "accuracy = accuracy_score(y_test_tensor.numpy(), y_pred_binary.numpy())\n",
    "print(\"Accuracy:\", accuracy)\n",
    "cm = confusion_matrix(y_test_tensor.numpy(), y_pred_binary.numpy())\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "auc = roc_auc_score(y_test_tensor.numpy(), y_pred.numpy())\n",
    "print(\"AUC-ROC:\", auc)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bcc7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 6: Random Forest\n",
    "\n",
    "# Copy of data for this model\n",
    "X_train = np.copy(X_train_common)\n",
    "y_train = np.copy(y_train_common)\n",
    "X_test = np.copy(X_test_common)\n",
    "y_test = np.copy(y_test_common)\n",
    "\n",
    "print(\"imblearn version:\", imblearn.__version__)\n",
    "\n",
    "print(\"Training data preview:\\n\", train_data.head())\n",
    "\n",
    "# Visualize original class distribution\n",
    "counter = Counter(y_train)\n",
    "print(\"\\nOriginal class distribution:\", counter)\n",
    "for label in counter:\n",
    "    row_ix = np.where(y_train == label)[0]\n",
    "    plt.scatter(X_train[row_ix, 0], X_train[row_ix, 1], label=f'Class {label}')\n",
    "plt.legend()\n",
    "plt.title('Original Data Distribution')\n",
    "plt.xlabel('Access')\n",
    "plt.ylabel('Tests')\n",
    "plt.show()\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# SMOTE\n",
    "oversample = SMOTE()\n",
    "X_train_res, y_train_res = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "# Visualize resampled\n",
    "counter_res = Counter(y_train_res)\n",
    "print(\"\\nResampled class distribution:\", counter_res)\n",
    "for label in counter_res:\n",
    "    row_ix = np.where(y_train_res == label)[0]\n",
    "    plt.scatter(X_train_res[row_ix, 0], X_train_res[row_ix, 1], label=f'Class {label}')\n",
    "plt.legend()\n",
    "plt.title('Resampled Data Distribution (SMOTE)')\n",
    "plt.xlabel('Access')\n",
    "plt.ylabel('Tests')\n",
    "plt.show()\n",
    "\n",
    "# Train Random Forest\n",
    "forest = RandomForestClassifier(\n",
    "    random_state=1,\n",
    "    n_estimators=1000,\n",
    "    max_features='sqrt',\n",
    "    max_depth=50,\n",
    "    bootstrap=False,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1\n",
    ")\n",
    "forest.fit(X_train_res, y_train_res)\n",
    "\n",
    "def evaluate(model, X, y):\n",
    "    predictions = model.predict(X)\n",
    "    errors = abs(predictions - y)\n",
    "    mape = mean_absolute_error(predictions, y) * 100\n",
    "    accuracy = 100 - mape\n",
    "    print(\"\\nModel Performance:\")\n",
    "    print(f\"Average Error: {np.mean(errors):.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "base_accuracy = evaluate(forest, X_test, y_test)\n",
    "\n",
    "y_pred_test = forest.predict(X_test)\n",
    "\n",
    "print(f\"\\nAccuracy Score: {accuracy_score(y_test, y_pred_test):.3f}\")\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "recall = 100 * cnf_matrix[1, 1] / (cnf_matrix[1, 0] + cnf_matrix[1, 1])\n",
    "print(f\"\\nRecall metric in the testing dataset: {recall:.2f}%\")\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0, 1], title='Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_test))\n",
    "\n",
    "y_pred_proba = forest.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUC-ROC:\", auc)\n",
    "plt.plot(fpr, tpr, label=f\"Random Forest, AUC={auc:.3f}\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred_test,\n",
    "    'Probability': y_pred_proba\n",
    "})\n",
    "results.to_csv('rf_predictions.csv', index=False)\n",
    "print(\"\\nPredictions saved to 'rf_predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef28ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 7: Support Vector Machine\n",
    "\n",
    "# Copy of data for this model\n",
    "X_train = np.copy(X_train_common)\n",
    "y_train = np.copy(y_train_common)\n",
    "X_test = np.copy(X_test_common)\n",
    "y_test = np.copy(y_test_common)\n",
    "\n",
    "print(\"imblearn version:\", imblearn.__version__)\n",
    "\n",
    "print(\"Training data preview:\\n\", train_data.head())\n",
    "\n",
    "# SMOTE\n",
    "oversample = SMOTE()\n",
    "X_train_res, y_train_res = oversample.fit_resample(X_train, y_train)\n",
    "print(\"\\nResampled training data shape:\", X_train_res.shape)\n",
    "\n",
    "# Train SVM\n",
    "svclassifier = SVC(\n",
    "    C=1.0,\n",
    "    kernel='linear',\n",
    "    degree=3,\n",
    "    gamma='auto',\n",
    "    probability=True\n",
    ")\n",
    "svclassifier.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Cross-val\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=1)\n",
    "scores = cross_val_score(svclassifier, X_test, y_test, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print(f\"\\nMean ROC AUC: {np.mean(scores):.3f}\")\n",
    "\n",
    "# Predictions\n",
    "yhat = svclassifier.predict(X_test)\n",
    "yhat_prob = svclassifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Unified Evaluation\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, yhat))\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "cm = confusion_matrix(y_test, yhat)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "auc = roc_auc_score(y_test, yhat_prob)\n",
    "print(\"AUC-ROC:\", auc)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=22)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, fontsize=13)\n",
    "    plt.yticks(tick_marks, classes, fontsize=13)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment='center',\n",
    "                 fontsize=15,\n",
    "                 color='white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Label', fontsize=16)\n",
    "    plt.xlabel('Predicted Label', fontsize=16)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, yhat, labels=[1, 0])\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['graduate=1', 'graduate=0'], normalize=False, title='Confusion Matrix')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, yhat_prob)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"Support Vector Machine, AUC={auc:.3f}\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69310889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 8: TabNet\n",
    "\n",
    "# Copy of data for this model\n",
    "X_train = np.copy(X_train_common)\n",
    "y_train = np.copy(y_train_common)\n",
    "X_test = np.copy(X_test_common)\n",
    "y_test = np.copy(y_test_common)\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# SMOTE\n",
    "oversample = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "# Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_res, y_train_res, test_size=0.2, random_state=42)\n",
    "\n",
    "# TabNet model\n",
    "model = TabNetClassifier(\n",
    "    n_d=32,\n",
    "    n_a=32,\n",
    "    n_steps=7,\n",
    "    gamma=1.3,\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=0.002),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_name=['val'],\n",
    "    eval_metric=['auc', 'accuracy'],\n",
    "    max_epochs=100,\n",
    "    patience=10,\n",
    "    batch_size=32,\n",
    "    virtual_batch_size=32,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Unified Evaluation\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(\"AUC-ROC:\", auc)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Passed', 'Passed'],\n",
    "            yticklabels=['Not Passed', 'Passed'])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'Enhanced TabNet, AUC={auc:.3f}', color='darkblue')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'Probability': y_pred_prob\n",
    "})\n",
    "results.to_csv('enhanced_tabnet_predictions.csv', index=False)\n",
    "print(\"\\nPredictions saved to 'enhanced_tabnet_predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4124b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 9: Attention-Augmented-Autoencoder\n",
    "\n",
    "# Copy of data for this model\n",
    "X_train = np.copy(X_train_common)\n",
    "y_train = np.copy(y_train_common)\n",
    "X_test = np.copy(X_test_common)\n",
    "y_test = np.copy(y_test_common)\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# SMOTE\n",
    "oversample = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "# Tensors\n",
    "X_train_tensor = torch.tensor(X_train_res, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_res, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_tensor, y_train_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# DataLoaders for autoencoder (input = output)\n",
    "train_dataset = TensorDataset(X_train, X_train)\n",
    "val_dataset = TensorDataset(X_val, X_val)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# AttentionLayer\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, feature_size):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.attention_weights = nn.Parameter(torch.randn(feature_size, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention_scores = torch.matmul(x, self.attention_weights)\n",
    "        attention_scores = torch.softmax(attention_scores, dim=1)\n",
    "        weighted_x = x * attention_scores\n",
    "        return weighted_x\n",
    "\n",
    "# AttentionAutoencoder\n",
    "class AttentionAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size, encoding_size):\n",
    "        super(AttentionAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            AttentionLayer(64),\n",
    "            nn.Linear(64, encoding_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, input_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Classifier\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, encoding_size):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc = nn.Linear(encoding_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "input_size = 3\n",
    "encoding_size = 32\n",
    "\n",
    "attention_autoencoder = AttentionAutoencoder(input_size, encoding_size)\n",
    "classifier = Classifier(encoding_size)\n",
    "\n",
    "ae_criterion = nn.SmoothL1Loss()\n",
    "ae_optimizer = optim.Adam(attention_autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "epochs_ae = 50\n",
    "for epoch in range(epochs_ae):\n",
    "    attention_autoencoder.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, _ in train_loader:\n",
    "        ae_optimizer.zero_grad()\n",
    "        output = attention_autoencoder(X_batch)\n",
    "        loss = ae_criterion(output, X_batch)\n",
    "        loss.backward()\n",
    "        ae_optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    print(f\"Attention Autoencoder Epoch [{epoch + 1}/{epochs_ae}], Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "attention_autoencoder.eval()\n",
    "with torch.no_grad():\n",
    "    X_train_encoded = attention_autoencoder.encoder(X_train).cpu().numpy()\n",
    "    X_val_encoded = attention_autoencoder.encoder(X_val).cpu().numpy()\n",
    "    X_test_encoded = attention_autoencoder.encoder(X_test_tensor).cpu().numpy()\n",
    "\n",
    "X_train_encoded = torch.tensor(X_train_encoded, dtype=torch.float32)\n",
    "X_val_encoded = torch.tensor(X_val_encoded, dtype=torch.float32)\n",
    "X_test_encoded = torch.tensor(X_test_encoded, dtype=torch.float32)\n",
    "\n",
    "train_dataset_class = TensorDataset(X_train_encoded, y_train)\n",
    "val_dataset_class = TensorDataset(X_val_encoded, y_val)\n",
    "test_dataset_class = TensorDataset(X_test_encoded, y_test_tensor)\n",
    "\n",
    "train_loader_class = DataLoader(train_dataset_class, batch_size=32, shuffle=True)\n",
    "val_loader_class = DataLoader(val_dataset_class, batch_size=32, shuffle=False)\n",
    "test_loader_class = DataLoader(test_dataset_class, batch_size=32, shuffle=False)\n",
    "\n",
    "clf_criterion = nn.BCELoss()\n",
    "clf_optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "patience = 5\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "epochs_clf = 50\n",
    "for epoch in range(epochs_clf):\n",
    "    classifier.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader_class:\n",
    "        clf_optimizer.zero_grad()\n",
    "        output = classifier(X_batch)\n",
    "        loss = clf_criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        clf_optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader_class)\n",
    "\n",
    "    classifier.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader_class:\n",
    "            output = classifier(X_batch)\n",
    "            loss = clf_criterion(output, y_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader_class)\n",
    "    print(f\"Classifier Epoch [{epoch + 1}/{epochs_clf}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_prob = classifier(X_test_encoded)\n",
    "    y_pred = (y_pred_prob > 0.5).float()\n",
    "\n",
    "# Unified Evaluation\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_tensor.numpy(), y_pred.numpy()))\n",
    "accuracy = accuracy_score(y_test_tensor.numpy(), y_pred.numpy())\n",
    "print(\"Accuracy:\", accuracy)\n",
    "cm = confusion_matrix(y_test_tensor.numpy(), y_pred.numpy())\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "auc = roc_auc_score(y_test_tensor.numpy(), y_pred_prob.numpy())\n",
    "print(\"AUC-ROC:\", auc)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Passed', 'Passed'],\n",
    "            yticklabels=['Not Passed', 'Passed'])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test_tensor.numpy(), y_pred_prob.numpy())\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'Attention Autoencoder, AUC={auc:.3f}', color='darkblue')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Actual': y_test_tensor.numpy().flatten(),\n",
    "    'Predicted': y_pred.numpy().flatten(),\n",
    "    'Probability': y_pred_prob.numpy().flatten()\n",
    "})\n",
    "results.to_csv('attention_autoencoder_predictions.csv', index=False)\n",
    "print(\"\\nPredictions saved to 'attention_autoencoder_predictions.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5012bc85",
   "metadata": {},
   "source": [
    "**版权声明（Copyright Notice）**\n",
    "\n",
    "本项目中所有源代码及相关文件均由**姚宇倬**独立开发与完成，享有全部知识产权及最终解释权。\n",
    "\n",
    "本代码及相关资源仅限于科研与学术研究用途。\n",
    "严禁任何形式的商业使用（包括但不限于：产品化、盈利性服务、商业推广、技术转让等）。\n",
    "\n",
    "任何未经授权的复制、修改、传播、再发布、出售或商业化利用，均构成对本人知识产权的严重侵犯。\n",
    "本人将依法追究侵权者的法律责任，直至刑事责任。\n",
    "\n",
    "特此声明。\n",
    "\n",
    "作者：姚宇倬——华北理工大学\n",
    "研究方向：机器人工程、计算机视觉与深度学习\n",
    "电子邮箱：yaoyuzhuo6@gmail.com\n",
    "\n",
    "---\n",
    "\n",
    "**Copyright Notice**\n",
    "\n",
    "All source code and related files in this project are independently developed and completed by **Yao Yuzhuo**, who retains full intellectual property rights and final interpretation rights.\n",
    "\n",
    "The code and related resources are provided strictly for academic and research purposes only.\n",
    "Any form of commercial use is strictly prohibited, including but not limited to productization, profit-making services, commercial promotion, or technology transfer.\n",
    "\n",
    "Any unauthorized reproduction, modification, distribution, republication, sale, or commercialization constitutes a serious infringement of the author's intellectual property rights.\n",
    "The author reserves the right to pursue legal liability, including civil and criminal responsibility, against any infringer.\n",
    "\n",
    "Author: Yao Yuzhuo——North China University of Science and Technology\n",
    "Research Focus: Robotics Engineering, Computer Vision, Deep Learning\n",
    "Email：yaoyuzhuo6@gmail.com\n",
    "\n",
    "---\n",
    "\n",
    "二零二五年-九月七日-白露\n",
    "2025-9-7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
